import java.util.Properties
import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer, ConsumerRecords, OffsetAndMetadata}
import org.apache.kafka.common.TopicPartition
import scala.collection.JavaConverters._

object KafkaConsumerExample {
  def main(args: Array[String]): Unit = {
    // Define the Kafka broker(s) and consumer properties
    val props = new Properties()
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
    props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-consumer-group")
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer")
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer")
    
    // Create a Kafka consumer instance
    val consumer = new KafkaConsumer[String, String](props)
    
    // Subscribe to the topic(s) you want to consume from
    val topics = List("my-topic")
    consumer.subscribe(topics.asJava)
    
    // Start consuming messages
    while (true) {
      val records: ConsumerRecords[String, String] = consumer.poll(100) // Poll for new messages every 100 milliseconds
      
      // Process the received records
      records.asScala.foreach { record =>
        val topic = record.topic()
        val key = record.key()
        val value = record.value()
        val partition = record.partition()
        val offset = record.offset()
        
        println(s"Received message: topic = $topic, key = $key, value = $value, partition = $partition, offset = $offset")
        
        // You can process the message here as needed
      }
      
      // Manually commit the offsets if you want to control when to mark messages as processed
      val offsetsToCommit = records.partitions().asScala.map { partition =>
        partition -> new OffsetAndMetadata(consumer.position(partition))
      }.toMap.asJava
      
      consumer.commitSync(offsetsToCommit)
    }
  }
}









import java.util.Properties
import org.apache.kafka.clients.consumer.{ConsumerConfig, KafkaConsumer, ConsumerRecords}
import org.apache.kafka.common.serialization.StringDeserializer
import scala.collection.JavaConverters._

object KafkaTopicReader {
  def main(args: Array[String]): Unit = {
    // Define the Kafka broker(s) and consumer properties
    val props = new Properties()
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
    props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-consumer-group")
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, classOf[StringDeserializer].getName)

    // Create a Kafka consumer instance
    val consumer = new KafkaConsumer[String, String](props)

    // Subscribe to the topic(s) you want to consume from
    val topics = List("my-topic")
    consumer.subscribe(topics.asJava)

    // Start consuming messages
    while (true) {
      val records: ConsumerRecords[String, String] = consumer.poll(100) // Poll for new messages every 100 milliseconds

      // Process the received records
      records.asScala.foreach { record =>
        val topic = record.topic()
        val key = record.key()
        val value = record.value()
        val partition = record.partition()
        val offset = record.offset()

        println(s"Received message: topic = $topic, key = $key, value = $value, partition = $partition, offset = $offset")

        // You can process the message here as needed
      }
    }
  }
}

